{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from s2cnn.nn.soft.so3_conv import SO3Convolution\n",
    "from s2cnn.nn.soft.s2_conv import S2Convolution\n",
    "from s2cnn.nn.soft.so3_integrate import so3_integrate\n",
    "from s2cnn.ops.so3_localft import near_identity_grid as so3_near_identity_grid\n",
    "from s2cnn.ops.s2_localft import near_identity_grid as s2_near_identity_grid\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import gzip, pickle\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def n2p(x, requires_grad = True):\n",
    "    \"\"\"converts numpy tensor to pytorch variable\"\"\"\n",
    "    return Variable(torch.Tensor(x), requires_grad)\n",
    "\n",
    "# https://github.com/pytorch/pytorch/issues/2591\n",
    "def logsumexp(inputs, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable logsumexp.\n",
    "\n",
    "    Args:\n",
    "        inputs: A Variable with any shape.\n",
    "        dim: An integer.\n",
    "        keepdim: A boolean.\n",
    "\n",
    "    Returns:\n",
    "        Equivalent of log(sum(exp(inputs), dim=dim, keepdim=keepdim)).\n",
    "    \"\"\"\n",
    "    # For a 1-D array x (any array along a single dimension),\n",
    "    # log sum exp(x) = s + log sum exp(x - s)\n",
    "    # with s = max(x) being a common choice.\n",
    "    if dim is None:\n",
    "        inputs = inputs.view(-1)\n",
    "        dim = 0\n",
    "    s, _ = torch.max(inputs, dim=dim, keepdim=True)\n",
    "    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\n",
    "    if not keepdim:\n",
    "        outputs = outputs.squeeze(dim)\n",
    "    return outputs\n",
    "\n",
    "class SO3reparameterize(nn.Module):\n",
    "    def __init__(self,input_dim, k=10):\n",
    "        super(SO3reparameterize, self).__init__()\n",
    "            \n",
    "        self.input_dim = input_dim\n",
    "        self.z_dim = 3\n",
    "        self.k = k\n",
    "        \n",
    "        self.mu_linear = nn.Linear(input_dim, 3)\n",
    "        self.Ldiag_linear = nn.Linear(input_dim, 3)\n",
    "        self.Lnondiag_linear = nn.Linear(input_dim, 3)\n",
    "          \n",
    "    @staticmethod\n",
    "    def _lieAlgebra(v):\n",
    "        \"\"\"Map a point in R^N to the tangent space at the identity, i.e. \n",
    "        to the Lie Algebra\n",
    "        Arg:\n",
    "            v = vector in R^N, (..., 3) in our case\n",
    "        Return:\n",
    "            R = v converted to Lie Algebra element, (3,3) in our case\"\"\"\n",
    "        R_x = n2p(np.array([[ 0., 0., 0.],[ 0., 0.,-1.],[ 0., 1., 0.]]))\n",
    "        R_y = n2p(np.array([[ 0., 0., 1.],[ 0., 0., 0.],[-1., 0., 0.]]))\n",
    "        R_z = n2p(np.array([[ 0.,-1., 0.],[ 1., 0., 0.],[ 0., 0., 0.]]))\n",
    "\n",
    "        R = R_x * v[..., 0, None, None] + R_y * v[..., 1, None, None] + \\\n",
    "            R_z * v[..., 2, None, None]\n",
    "        return R\n",
    "    \n",
    "    @staticmethod\n",
    "    def _expmap_rodrigues(v):\n",
    "        theta = v.norm(p=2,dim=-1, keepdim=True)\n",
    "        K = SO3reparameterize._lieAlgebra(v/theta)\n",
    "        I = Variable(torch.eye(3))\n",
    "        R = I + torch.sin(theta)[...,None]*K + \\\n",
    "                (1. - torch.cos(theta))[...,None]*(K@K)\n",
    "        a = torch.sin(theta)[...,None]\n",
    "        return R\n",
    "    \n",
    "    def forward(self, x, n=1):\n",
    "        self.mu = self.mu_linear(x)\n",
    "        self.D = F.softplus(self.Ldiag_linear(x))\n",
    "        L = self.Lnondiag_linear(x)\n",
    "\n",
    "        self.L = torch.cat((Variable(torch.ones(torch.Size((*self.D.size()[:-1], 1)))),\n",
    "                       Variable(torch.zeros(torch.Size((*self.D.size()[:-1], 2)))),\n",
    "                       L[...,0].unsqueeze(-1),\n",
    "                       Variable(torch.ones(torch.Size((*self.D.size()[:-1], 1)))),\n",
    "                       Variable(torch.zeros(torch.Size((*self.D.size()[:-1], 1)))),\n",
    "                       L[...,1:],\n",
    "                       Variable(torch.ones(torch.Size((*self.D.size()[:-1], 1))))), -1).view(\n",
    "            torch.Size((*self.D.size()[:-1], 3, 3)))\n",
    "        \n",
    "        self.v, self.z = self.nsample(self.mu, self.L, self.D, n = n)\n",
    "        \n",
    "        return self.z\n",
    "    \n",
    "    def kl(self):\n",
    "        kl = 0\n",
    "        return kl\n",
    "            \n",
    "    def log_posterior(self):\n",
    "        theta = self.v.norm(p=2,dim=-1, keepdim=True)\n",
    "        u = self.v / theta\n",
    "        angles = Variable(torch.arange(-self.k, self.k+1) * 2 * math.pi)\n",
    "        theta_hat = theta[...,None] + angles\n",
    "        x = u[...,None] * theta_hat\n",
    "\n",
    "        L_hat = self.L - Variable(torch.eye(3))\n",
    "        L_inv = Variable(torch.eye(3)) - L_hat + L_hat@L_hat\n",
    "        D_inv = 1. / self.D\n",
    "        A = L_inv @ x\n",
    "\n",
    "        p = -0.5*(A * D_inv[...,None] * A + 2 * torch.log(theta_hat.abs()) -\\\n",
    "                          torch.log(2 - 2 * torch.cos(theta_hat))).sum(-2) \n",
    "        p = logsumexp(p, -1)\n",
    "        p += -0.5*(torch.log(self.D.prod(-1)) + self.v.size()[-1]*math.log(2.*math.pi))\n",
    "\n",
    "        return p\n",
    "        \n",
    "    def log_prior(self):\n",
    "        # To DO :\n",
    "        return 1 / (8 * math.pi**2)\n",
    "        \n",
    "    @staticmethod\n",
    "    def nsample(mu, L, D, n=1):\n",
    "        # reproduce the decomposition of L-D we make\n",
    "        eps = Normal(torch.zeros_like(mu), torch.ones_like(mu)).sample_n(n) \n",
    "        v = (L @ (D.pow(0.5)*eps)[..., None]).squeeze(-1)\n",
    "        mu_lie = SO3reparameterize._expmap_rodrigues(mu)\n",
    "        v_lie = SO3reparameterize._expmap_rodrigues(v)\n",
    "        return v, mu_lie @ v_lie\n",
    "    \n",
    "s3 = SO3reparameterize(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniform_over_ball(n, r=math.pi, d=3):\n",
    "    a = np.random.normal(0,1,(n,d))\n",
    "    a = a/np.linalg.norm(a,2,-1, True)\n",
    "    u = np.random.uniform(0,1,(n,1))**(1/d)\n",
    "    \n",
    "    #using https://www.sciencedirect.com/science/article/pii/S0047259X10001211\n",
    "    return a*u*r, u*r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nprodrigues(v):\n",
    "    return SO3reparameterize._expmap_rodrigues(n2p(v)).data.numpy()\n",
    "\n",
    "\n",
    "def E(samples, f, w = np.array([1])):\n",
    "    return (f(samples)*w[:,None,None]).mean(0)\n",
    "\n",
    "def volume(s_norm):\n",
    "    return np.squeeze(2*(1 - np.cos(s_norm))/(s_norm**2))\n",
    "\n",
    "\n",
    "def rot2norm(R):  \n",
    "    a = np.trace(R, axis1=-2, axis2=-1)/2 - 1/2\n",
    "    a = np.clip(a, -1, 1)\n",
    "    return np.absolute(np.arccos(a))\n",
    "\n",
    "def rot2vol(R):\n",
    "    return volume(rot2norm(R))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s, s_norm = uniform_over_ball(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_norm = np.squeeze(s_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = np.random.uniform(0,10, (1,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s, s_norm = uniform_over_ball(100000)\n",
    "\n",
    "s_norm = np.squeeze(s_norm)\n",
    "\n",
    "g = nprodrigues(s)\n",
    "\n",
    "vol = volume(s_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda x: mat.transpose(0,2,1)@(x@mat)\n",
    "E(g,f,vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu = uniform_over_ball(1)[0]\n",
    "mu_lie = nprodrigues(mu)\n",
    "g_rot = mu_lie@g\n",
    "vol_rot = rot2vol(g_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E(g_rot,f,vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
