{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from s2cnn.nn.soft.so3_conv import SO3Convolution\n",
    "from s2cnn.nn.soft.s2_conv import S2Convolution\n",
    "from s2cnn.nn.soft.so3_integrate import so3_integrate\n",
    "from s2cnn.ops.so3_localft import near_identity_grid as so3_near_identity_grid\n",
    "from s2cnn.ops.s2_localft import near_identity_grid as s2_near_identity_grid\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import gzip, pickle\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from vae.pytorch_util import t2p, n2p\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Nreparameterize(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, z_dim):\n",
    "        super(Nreparameterize, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.sigma_linear = nn.Linear(input_dim, z_dim)\n",
    "        self.mu_linear = nn.Linear(input_dim, z_dim)\n",
    "\n",
    "    def forward(self, x, n=1):\n",
    "        self.mu = self.mu_linear(x)\n",
    "        self.sigma = F.softplus(self.sigma_linear(x))\n",
    "        self.z = self.nsample(n=n)\n",
    "        return self.z\n",
    "\n",
    "    def kl(self):\n",
    "        return -0.5 * torch.sum(1 + 2 * self.sigma.log() - self.mu.pow(2) - self.sigma ** 2, -1)\n",
    "    \n",
    "    def log_posterior(self):\n",
    "        return self._log_posterior(self.z)\n",
    "\n",
    "    def _log_posterior(self, z):\n",
    "        return Normal(self.mu, self.sigma).log_prob(z)\n",
    "\n",
    "    def log_prior(self):\n",
    "        return Normal(torch.zeros_like(self.mu), torch.ones_like(self.sigma)).log_prob(self.z)\n",
    "   \n",
    "    def nsample(self, n=1):\n",
    "        eps = Normal(torch.zeros_like(self.mu), torch.ones_like(self.mu)).sample_n(n)\n",
    "        return self.mu + eps * self.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://github.com/pytorch/pytorch/issues/2591\n",
    "def logsumexp(inputs, dim=None, keepdim=False):\n",
    "    \"\"\"Numerically stable logsumexp.\n",
    "\n",
    "    Args:\n",
    "        inputs: A Variable with any shape.\n",
    "        dim: An integer.\n",
    "        keepdim: A boolean.\n",
    "\n",
    "    Returns:\n",
    "        Equivalent of log(sum(exp(inputs), dim=dim, keepdim=keepdim)).\n",
    "    \"\"\"\n",
    "    # For a 1-D array x (any array along a single dimension),\n",
    "    # log sum exp(x) = s + log sum exp(x - s)\n",
    "    # with s = max(x) being a common choice.\n",
    "    if dim is None:\n",
    "        inputs = inputs.view(-1)\n",
    "        dim = 0\n",
    "    s, _ = torch.max(inputs, dim=dim, keepdim=True)\n",
    "    outputs = s + (inputs - s).exp().sum(dim=dim, keepdim=True).log()\n",
    "    if not keepdim:\n",
    "        outputs = outputs.squeeze(dim)\n",
    "    return outputs\n",
    "\n",
    "class SO3reparameterize(nn.Module):\n",
    "    def __init__(self, reparameterize, k=10):\n",
    "        super(SO3reparameterize, self).__init__()\n",
    "            \n",
    "        self.reparameterize = reparameterize\n",
    "        self.input_dim = self.reparameterize.input_dim\n",
    "        assert self.reparameterize.z_dim == 3\n",
    "        self.k = k\n",
    "        \n",
    "        self.mu_linear = nn.Linear(self.input_dim, 3)\n",
    "       \n",
    "          \n",
    "    @staticmethod\n",
    "    def _lieAlgebra(v):\n",
    "        \"\"\"Map a point in R^N to the tangent space at the identity, i.e. \n",
    "        to the Lie Algebra\n",
    "        Arg:\n",
    "            v = vector in R^N, (..., 3) in our case\n",
    "        Return:\n",
    "            R = v converted to Lie Algebra element, (3,3) in our case\"\"\"\n",
    "        is_cuda = v.is_cuda\n",
    "        R_x = n2p(np.array([[ 0., 0., 0.],[ 0., 0.,-1.],[ 0., 1., 0.]]), cuda = is_cuda)\n",
    "        R_y = n2p(np.array([[ 0., 0., 1.],[ 0., 0., 0.],[-1., 0., 0.]]), cuda = is_cuda)\n",
    "        R_z = n2p(np.array([[ 0.,-1., 0.],[ 1., 0., 0.],[ 0., 0., 0.]]), cuda = is_cuda)\n",
    "\n",
    "        R = R_x * v[..., 0, None, None] + R_y * v[..., 1, None, None] + \\\n",
    "            R_z * v[..., 2, None, None]\n",
    "        return R\n",
    "    \n",
    "    @staticmethod\n",
    "    def _expmap_rodrigues(v):\n",
    "        is_cuda = v.is_cuda\n",
    "        theta = v.norm(p=2,dim=-1, keepdim=True)\n",
    "        K = SO3reparameterize._lieAlgebra(v/theta)\n",
    "        I = Variable(torch.eye(3))\n",
    "        I = I.cuda() if is_cuda else I\n",
    "        R = I + torch.sin(theta)[...,None]*K + \\\n",
    "                (1. - torch.cos(theta))[...,None]*(K@K)\n",
    "        a = torch.sin(theta)[...,None]\n",
    "        return R\n",
    "    \n",
    "    def forward(self, x, n=1):\n",
    "        self.mu = self.mu_linear(x)\n",
    "        self.v = self.reparameterize(x, n)\n",
    "        \n",
    "        self.z = self.nsample(n = n)\n",
    "        \n",
    "        return self.v, self.z\n",
    "    \n",
    "    def kl(self):\n",
    "        log_q_z_x = self.log_posterior()\n",
    "        log_p_z = self.log_prior()\n",
    "        kl = log_q_z_x - log_p_z\n",
    "        return kl.mean(0)\n",
    "            \n",
    "    def log_posterior(self):\n",
    "        \n",
    "        theta = self.v.norm(p=2,dim=-1, keepdim=True) #[n,B,1]\n",
    "    \n",
    "        u = self.v / theta #[n,B,3]\n",
    "        angles = Variable(torch.arange(-self.k, self.k+1) * 2 * math.pi) #[2k+1]\n",
    "        angles = angles.cuda() if self.v.is_cuda else angles\n",
    "         \n",
    "        theta_hat = theta[..., None, :] + angles[:,None] #[n,B,2k+1,1]\n",
    "        \n",
    "        x = u[...,None,:] * theta_hat #[n,B,2k+1,3]\n",
    "              \n",
    "        log_p = self.reparameterize._log_posterior(x.permute([0,2,1,3])) #[n,(2k+1),B,3] or [n,(2k+1),B]\n",
    "        # maybe reduce last dimension\n",
    "        if len(log_p.size()) == 4:\n",
    "\n",
    "            log_p = log_p.sum(-1) # [n,(2k+1),B]\n",
    "            \n",
    "        log_p = log_p.permute([0,2,1]) # [n,B,(2k+1)]\n",
    "        \n",
    "        log_vol = 2 * torch.log(theta_hat.abs()) - torch.log(2 - 2 * torch.cos(theta_hat)) #[n,B,(2k+1),1]\n",
    "        \n",
    "        log_p = log_p*log_vol.sum(-1)\n",
    "        \n",
    "        log_p = logsumexp(log_p, -1)\n",
    "       \n",
    "        return log_p\n",
    "        \n",
    "    def log_prior(self):\n",
    "        is_cuda = self.v.is_cuda\n",
    "        prior = t2p(torch.Tensor([1 / (8 * math.pi ** 2)]), cuda=is_cuda)\n",
    "        return (prior.log()).expand_as(self.z[...,0,0])\n",
    "        \n",
    "\n",
    "    def nsample(self, n=1):\n",
    "        # reproduce the decomposition of L-D we make\n",
    "        \n",
    "        mu_lie = SO3reparameterize._expmap_rodrigues(self.mu)\n",
    "        v_lie = SO3reparameterize._expmap_rodrigues(self.v)\n",
    "        return mu_lie @ v_lie\n",
    " \n",
    "#n = Nreparameterize(10,3)\n",
    "#s3 = SO3reparameterize(n, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unifinished \n",
    "class Mul3Nreparameterize(nn.Module):\n",
    "     def __init__(self, input_dim, z_dim):\n",
    "        super(Nreparameterize, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.L_linear = nn.Linear(input_dim, int(z_dim*(z_dim-1)/2))\n",
    "        self.D_linear = nn.Linear(input_dim, z_dim)\n",
    "        self.mu_linear = nn.Linear(input_dim, z_dim)\n",
    "\n",
    "    def forward(self, x, n=1):\n",
    "        self.mu = self.mu_linear(x)\n",
    "        self.L = self.sigma_linear(x)\n",
    "        self.D = F.softplus(self.D_linear(x))\n",
    "        self.L = unit_triangular(self.L_linear(x))\n",
    "        self.z = self.nsample(n=n)\n",
    "        return self.z\n",
    "\n",
    "    def kl(self):\n",
    "        return -0.5 * torch.sum(1 + 2 * self.sigma.log() - self.mu.pow(2) - self.sigma ** 2, -1)\n",
    "    \n",
    "    def log_posterior(self):\n",
    "        return self._log_posterior(self.z)\n",
    "\n",
    "    def _log_posterior(self, z):\n",
    "        return Normal(self.mu, self.sigma).log_prob(z)\n",
    "\n",
    "    def log_prior(self):\n",
    "        return Normal(torch.zeros_like(self.mu), torch.ones_like(self.sigma)).log_prob(self.z)\n",
    "   \n",
    "    def nsample(self, n=1):\n",
    "        eps = Normal(torch.zeros_like(self.mu), torch.ones_like(self.mu)).sample_n(n)\n",
    "        return self.mu + eps * self.sigma\n",
    "    \n",
    "    @staticmethod \n",
    "    def unit_triangular(x):\n",
    "    shape, dim = x.size()[:-1], x.size()[-1]\n",
    "    n = (1 + math.sqrt(1+8*dim)) / 2\n",
    "    assert int(n) - n == 0\n",
    "    n = int(n)\n",
    "    r,c = np.tril_indices(n,-1)\n",
    "    eye = Variable(torch.eye(n).expand(*shape,-1,-1)).clone()\n",
    "    eye = eye.cuda() if x.is_cuda else eye\n",
    "    eye[...,r,c] = x\n",
    "    return eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(Normal(torch.zeros(10), torch.ones(10)).sample_n(5))\n",
    "s3(x, 300)\n",
    "print(s3.kl())\n",
    "n.kl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3(x, 1)\n",
    "s3.kl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p[0,0,:].data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.view(1,2,*tuple([1]*0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  Variable(Normal(torch.zeros(3), torch.ones(3)).sample_n(2), requires_grad = True)\n",
    "zeros = Variable(torch.zeros(2,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c = np.tril_indices(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros[:,r,c] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_triangular(x):\n",
    "    shape, dim = x.size()[:-1], x.size()[-1]\n",
    "    n = (1 + math.sqrt(1+8*dim)) / 2\n",
    "    assert int(n) - n == 0\n",
    "    n = int(n)\n",
    "    r,c = np.tril_indices(n,-1)\n",
    "    eye = Variable(torch.eye(n).expand(*shape,-1,-1)).clone()\n",
    "    eye = eye.cuda() if x.is_cuda else eye\n",
    "    eye[...,r,c] = x\n",
    "    return eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "B = 2\n",
    "dim = int(n*(n-1)/2)\n",
    "x =  Variable(Normal(torch.zeros(dim), torch.ones(dim)).sample_n(2), requires_grad = True)\n",
    "unit_triangular(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.eye(3).expand(4,5,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch3]",
   "language": "python",
   "name": "conda-env-pytorch3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
