{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os.path\n",
    "from PIL import Image\n",
    "from lie_learn.groups.SO3 import change_coordinates as SO3_coordinates\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "from lie_vae.vae import CubeVAE\n",
    "from lie_vae.reparameterize import Nreparameterize, SO3reparameterize, N0reparameterize\n",
    "from lie_vae.utils import MLP, random_split, View, Flatten\n",
    "from lie_vae.lie_tools import group_matrix_to_eazyz, block_wigner_matrix_multiply\n",
    "from lie_vae.datasets import CubeDataset\n",
    "from lie_vae.nets import CubesDeconvNet, CubesConvNet\n",
    "from lie_vae.decoders import ActionNet, MLPNet\n",
    "\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--latent', '-z', type=str, default='so3', help='normal or so3')\n",
    "parser.add_argument('--decoder', '-d', type=str, default='mlp', help='mlp or action')\n",
    "parser.add_argument('--epochs', '-e', type=int, default=1, help='')\n",
    "parser.add_argument('--load', '-l', type=str, default='', help='')\n",
    "parser.add_argument('--save', '-s', type=str, default='', help='')\n",
    "parser.add_argument('--batch_dim', '-b', type=int, default=32, help='')\n",
    "parser.add_argument('--batch_norm', '-bn', , action='store_true')\n",
    "\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CubeDataset('train')\n",
    "dev_dataset = CubeDataset('dev')\n",
    "test_dataset = CubeDataset('test')\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset, batch_size=FLAGS.batch_dim, shuffle=True)\n",
    "dev_loader = data_utils.DataLoader(dev_dataset, batch_size=FLAGS.batch_dim, shuffle=True)\n",
    "test_loader = data_utils.DataLoader(test_dataset, batch_size=FLAGS.batch_dim, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CubeVAE(FLAGS.decoder, FLAGS.latent, FLAGS.batch_norm).to(device)\n",
    "\n",
    "if FLAGS.load != '':\n",
    "    model = torch.load(FLAGS.load)\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"training {} with {}\".format(FLAGS.latent, FLAGS.decoder))\n",
    "for j in range(FLAGS.epochs):\n",
    "    for i, (images, ) in enumerate(train_loader):\n",
    "        images = Variable(images).cuda() if CUDA else Variable(images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_recon, loss_kl = model.elbo(images, n=1)\n",
    "        \n",
    "        loss_recon = loss_recon.mean()\n",
    "        loss_kl = loss_kl.mean()\n",
    "        loss = loss_recon + loss_kl\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('\\r epoch: {:4}/{:4}, it: {:4}/{:4}: ELBO: {:.4f}, recon: {:.4f}, KL: {:.4f}'.format(\n",
    "                j, FLAGS.epochs, i, len(train_loader),\n",
    "                float(loss.data.cpu().numpy()),\n",
    "                float(loss_recon.data.cpu().numpy()),\n",
    "                float(loss_kl.data.cpu().numpy())),\n",
    "            end='')\n",
    "\n",
    "    if FLAGS.save != '':\n",
    "        torch.save(model, FLAGS.save)\n",
    "    \n",
    "    loss_recon, loss_kl = np.array([[loss_recon.mean().data.cpu().numpy(), loss_kl.mean().data.cpu().numpy()] \n",
    "          for loss_recon, loss_kl in model.elbo(Variable(images).cuda() if CUDA else Variable(images))\n",
    "     for i, (images, ) in enumerate(dev_loader)]).mean(0)\n",
    "    \n",
    "    print('\\r epoch: {:4}/{:4}, it: {:4}/{:4}: ELBO: {:.4f}, recon: {:.4f}, KL: {:.4f}'.format(\n",
    "        j, FLAGS.epochs, i, len(train_loader), loss_recon + loss_kl, loss_recon, loss_kl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_recon, loss_kl = np.array([[loss_recon.mean().data.cpu().numpy(), loss_kl.mean().data.cpu().numpy()] \n",
    "      for loss_recon, loss_kl in model.elbo(Variable(images).cuda() if CUDA else Variable(images))\n",
    " for i, (images, ) in enumerate(test_loader)]).mean(0)\n",
    "\n",
    "ll = np.array([model.log_likelihood(Variable(images).cuda() if CUDA else Variable(images), n=500).data.cpu().numpy()\n",
    " for i, (images, ) in enumerate(test_loader)]).mean()\n",
    "\n",
    "print(\"TEST VAE CUBES results for {} with {}  ---  {} epochs \".format(FLAGS.latent, FLAGS.decoder, FLAGS.epochs))\n",
    "print('ELBO: {:.4f}, recon: {:.4f}, KL: {:.4f}, LL: {:.4f}'.format(\n",
    "    loss_recon + loss_kl, loss_recon, loss_kl, ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(next(iter(train_loader))[0][0:1])\n",
    "rec_img = model(img.cuda() if CUDA else img)\n",
    "\n",
    "plt.imshow(img.data.cpu().numpy()[0].transpose(1, 2, 0))\n",
    "plt.show()\n",
    "plt.imshow(F.sigmoid(rec_img).data.cpu().numpy()[0,0].transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Continuity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degrees = 3\n",
    "# matrix_dims = (degrees + 1) ** 2\n",
    "# in_dims = 2\n",
    "# item_rep = nn.Parameter(torch.randn((matrix_dims, in_dims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 1000\n",
    "# x0 = np.random.normal(0,0.001,(N+1,3))\n",
    "# print(x0.shape)\n",
    "# x0 = np.cumsum(np.cumsum(x0,-2), -2)\n",
    "# print(x0.shape)\n",
    "# x0 = torch.tensor(x0, dtype = torch.float32)\n",
    "# group_el = SO3reparameterize._expmap_rodrigues(x0)\n",
    "# angles = group_matrix_to_eazyz(group_el)\n",
    "\n",
    "\n",
    "# plt.plot(angles.detach().numpy()[:,0], \"o\", color = \"b\")\n",
    "# plt.show()\n",
    "# plt.plot(angles.detach().numpy()[:,1], \"o\", color = \"b\")\n",
    "# plt.show()\n",
    "# plt.plot(angles.detach().numpy()[:,2], \"o\", color = \"b\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n = angles.size(0)\n",
    "# item_expanded = item_rep.expand(n, -1, -1)\n",
    "# item = block_wigner_matrix_multiply(angles, item_expanded, degrees) \\\n",
    "#             .view(-1, matrix_dims * in_dims)\n",
    "\n",
    "# i = np.random.randint(item.shape[1])\n",
    "   \n",
    "# plt.plot(item.detach().numpy()[:,i], \"o\", color = \"b\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.arange(-3, 4) * 2 * math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
