{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import gzip\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from s2cnn.nn.soft.so3_conv import SO3Convolution\n",
    "from s2cnn.nn.soft.s2_conv import S2Convolution\n",
    "from s2cnn.nn.soft.so3_integrate import so3_integrate\n",
    "from s2cnn.ops.so3_localft import near_identity_grid as so3_near_identity_grid\n",
    "from s2cnn.ops.s2_localft import near_identity_grid as s2_near_identity_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_util import load_mnist_data, n2p\n",
    "from vae import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gpu', '-g', type=int, default=0, help='')\n",
    "parser.add_argument('--epochs', '-e', type=int, default=10, help='')\n",
    "parser.add_argument('--batch_dim', '-bd', type=int, default=32, help='')\n",
    "parser.add_argument('--learning_rate', '-lr', type=float, default=1e-3, help='')\n",
    "\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, train_dataset, _ = load_mnist_data('../mnist_example/s2_mnist.gz', FLAGS.batch_dim)\n",
    "torch.cuda.set_device(FLAGS.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dims=[10, 3]\n",
    "encoder_f=[1, 10, 10]\n",
    "decoder_f=[10, 10, 1]\n",
    "encoder_b=[30, 20, 6]\n",
    "decoder_b=[5, 15, 30]\n",
    "latents = ['gaussian', 'gaussian']\n",
    "callbacks = [{'type':'invariant',\n",
    "           'mlp_h': [100]},\n",
    "          {'type':'equivariant', \n",
    "           'f_list':[1],\n",
    "           'b_list':[6], \n",
    "           'mlp_h': [100]}]\n",
    "decoder_mlp_h=[100]\n",
    "\n",
    "vae = NS2VAE(z_dims=z_dims,\n",
    "             encoder_f=encoder_f,\n",
    "             decoder_f=decoder_f,\n",
    "             encoder_b=encoder_b,\n",
    "             decoder_b=decoder_b,\n",
    "             latents = latents,\n",
    "             callbacks = callbacks,\n",
    "             decoder_mlp_h=decoder_mlp_h,\n",
    "             max_pooling=False)\n",
    "print(\"#params\", sum([x.numel() for x in vae.parameters()]))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda(FLAGS.gpu)\n",
    "\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=FLAGS.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(FLAGS.epochs):\n",
    "    print ('\\nepoch: %d/%d' % (epoch+1, FLAGS.epochs))\n",
    "    ave_epoch_loss = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)/255\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda(FLAGS.gpu)\n",
    "            labels = labels.cuda(FLAGS.gpu)\n",
    "        \n",
    "        rec, kl = vae.elbo(images, n=1)\n",
    "        kl_w = 1.#float(np.minimum(0., i / (len(train_dataset) / FLAGS.batch_dim)))\n",
    "        elbo = rec.mean() + kl_w * kl.mean()\n",
    "        ave_epoch_loss.append(rec.cpu().data.numpy().mean())\n",
    "        elbo.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        print('\\r it: %d/%d \\t rec: %4.3f \\t kl: %4.3f' % \n",
    "              (i, int(len(train_dataset) / FLAGS.batch_dim), \\\n",
    "               rec.cpu().data.numpy().mean(), kl.cpu().data.numpy().mean()), end='')\n",
    "        \n",
    "        \n",
    "    print ('\\r ave elbo: %4.3f' % (np.asarray(ave_epoch_loss).mean()), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "b = 16\n",
    "idx = np.random.randint(0,b)\n",
    "plt.imshow(images[idx,0].cpu().data.numpy(), cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(F.sigmoid(vae(images)[idx, 0,]).cpu().data.numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.random.normal(0,1,(1, b ,13))\n",
    "z = vae.decode(n2p(c).cuda())\n",
    "idx = np.random.randint(0,16)\n",
    "plt.imshow(z[idx,0].cpu().data.numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.log_likelihood(images.cuda(FLAGS.gpu), n=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
