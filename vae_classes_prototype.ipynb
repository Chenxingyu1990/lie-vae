{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from s2cnn.nn.soft.so3_conv import SO3Convolution\n",
    "from s2cnn.nn.soft.s2_conv import S2Convolution\n",
    "from s2cnn.nn.soft.so3_integrate import so3_integrate\n",
    "from s2cnn.ops.so3_localft import near_identity_grid as so3_near_identity_grid\n",
    "from s2cnn.ops.s2_localft import near_identity_grid as s2_near_identity_grid\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import gzip, pickle\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self ,H = [1,10,1], activation = nn.ReLU):\n",
    "        super(MLP, self).__init__()\n",
    "        self.H = H\n",
    "        self.activation = activation()\n",
    "        modules = []\n",
    "        for input_dim, output_dim in zip (H, H[1:-1]):\n",
    "            modules.append(nn.Linear(input_dim, output_dim))\n",
    "            modules.append(self.activation)\n",
    "        modules.append(nn.Linear(H[-2],H[-1]))\n",
    "        self.module = nn.Sequential(*modules)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.module(x)\n",
    "        return y\n",
    "    \n",
    "class Nreparametrize(nn.Module):\n",
    "    def __init__(self,input_dim, z_dim):\n",
    "        super(Nreparametrize, self).__init__()\n",
    "            \n",
    "        self.input_dim = input_dim\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.sigma_linear = nn.Linear(input_dim, z_dim)\n",
    "        self.mu_linear = nn.Linear(input_dim, z_dim)\n",
    "        \n",
    "    def forward(self, x, n = 1):\n",
    "        x = F.relu(x)\n",
    "        self.mu = self.mu_linear(x)\n",
    "        self.log_sigma = self.sigma_linear(x)  \n",
    "        self.z = self.nsample(self.mu, self.log_sigma, n = n)\n",
    "        \n",
    "        return self.z\n",
    "    \n",
    "    \n",
    "    def kl(self):\n",
    "        return -0.5 * torch.sum(1 + 2*self.log_sigma - self.mu.pow(2) - self.log_sigma.exp()**2, -1)\n",
    "        \n",
    "        \n",
    "    def log_posterior(self):\n",
    "        raise Normal(self.mu, self.log_sigma.exp()).log_prob(self.z)\n",
    "        \n",
    "    def log_prior(self):\n",
    "        return Normal(torch.ones_like(self.mu), torch.zeros_like(self.log_sigma)).log_prob(self.z)\n",
    "        \n",
    "        \n",
    "    @staticmethod     \n",
    "    def nsample(mu, log_sigma, n = 1):\n",
    "        eps = Normal(torch.ones_like(mu), torch.zeros_like(mu)).sample_n(n)\n",
    "        return mu + eps*log_sigma.exp()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = None \n",
    "        self.decoder = None \n",
    "        self.reparametrize = [None]\n",
    "        \n",
    "        \n",
    "    def encode(self,x, n = 1):\n",
    "        h = self.encoder(x)\n",
    "        self.z = [r(h, n) for r in self.reparametrize]\n",
    "        return self.z\n",
    "    \n",
    "    def kl(self):\n",
    "        # NOTE always call after encode\n",
    "        # TODO make this bahaviour impossible\n",
    "        kl = [r.kl() for r in self.reparametrize]\n",
    "        return kl\n",
    "        \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.encode(x);\n",
    "    \n",
    "        # flatten and stack z\n",
    "        d0, d1 = self.z[0].size()[:2]\n",
    "        z_cat = torch.cat([v.view(d0,d1,-1) for v in self.z], -1)\n",
    "        \n",
    "        return self.decode(z_cat)\n",
    "    \n",
    "    @staticmethod\n",
    "    def recon_loss(x, x_recon):\n",
    "        raise NotImplemented \n",
    "    \n",
    "    def elbo(self,x):\n",
    "        x_recon = self.forward(x)\n",
    "        kl_summed  = torch.sum(torch.stack(kl,-1), -1)\n",
    "        recon_loss = self.recon_loss(x, x_recon)\n",
    "        return recon_loss, kl_summed\n",
    "        \n",
    "        \n",
    "    def log_likelihood(self, x):\n",
    "        raise NotImplemented       \n",
    "\n",
    "class NVAE(VAE):\n",
    "    def __init__(self, encoder_dims = [10, 7, 5], decoder_dims = [5,7,10]):\n",
    "        super(NVAE, self).__init__() \n",
    "        self.encoder_dims = encoder_dims\n",
    "        self.decoder_dims = decoder_dims\n",
    "        assert encoder_dims[-1] == decoder_dims[0]\n",
    "        self.encoder = MLP(self.encoder_dims[:-1])\n",
    "        self.decoder = MLP(self.decoder_dims)\n",
    "        self.reparametrize = [Nreparametrize(self.encoder_dims[-2], self.encoder_dims[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = NVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(Normal(torch.Tensor(np.zeros((10))), torch.Tensor(np.ones((10)))).sample_n(6))\n",
    "rec = vae(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.8103\n",
       " 0.7481\n",
       " 0.7372\n",
       " 1.7921\n",
       " 1.5197\n",
       " 0.7443\n",
       "[torch.FloatTensor of size 6]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.stack(kl,-1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Nreparametrize' object has no attribute 'log_sigma'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-594ac08cbaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-b845557b779c>\u001b[0m in \u001b[0;36mkl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# NOTE always call after encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparametrize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-b845557b779c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# NOTE always call after encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparametrize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6adcc871435f>\u001b[0m in \u001b[0;36mkl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_sigma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_sigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/luca/anaconda2/envs/pytorch3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 366\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Nreparametrize' object has no attribute 'log_sigma'"
     ]
    }
   ],
   "source": [
    "vae.kl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
