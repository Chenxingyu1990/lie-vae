{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from s2cnn.nn.soft.so3_conv import SO3Convolution\n",
    "from s2cnn.nn.soft.s2_conv import S2Convolution\n",
    "from s2cnn.nn.soft.so3_integrate import so3_integrate\n",
    "from s2cnn.ops.so3_localft import near_identity_grid as so3_near_identity_grid\n",
    "from s2cnn.ops.s2_localft import near_identity_grid as s2_near_identity_grid\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import gzip, pickle\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self ,H = [1,10,1], activation = nn.ReLU, end_activation = False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.H = H\n",
    "        self.activation = activation\n",
    "        modules = []\n",
    "        for input_dim, output_dim in zip (H, H[1:-1]):\n",
    "            modules.append(nn.Linear(input_dim, output_dim))\n",
    "            modules.append(self.activation())\n",
    "        modules.append(nn.Linear(H[-2],H[-1]))\n",
    "        if end_activation:\n",
    "            modules.append(self.activation())\n",
    "        self.module = nn.Sequential(*modules)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.module(x)\n",
    "        return y\n",
    "    \n",
    "class Nreparametrize(nn.Module):\n",
    "    def __init__(self,input_dim, z_dim):\n",
    "        super(Nreparametrize, self).__init__()\n",
    "            \n",
    "        self.input_dim = input_dim\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.sigma_linear = nn.Linear(input_dim, z_dim)\n",
    "        self.mu_linear = nn.Linear(input_dim, z_dim)\n",
    "        \n",
    "    def forward(self, x, n=1):\n",
    "        \n",
    "        self.mu = self.mu_linear(x)\n",
    "        \n",
    "        self.sigma = F.softplus(self.sigma_linear(x))\n",
    "        \n",
    "        \n",
    "        self.z = self.nsample(self.mu, self.sigma, n = n)\n",
    "        \n",
    "        return self.z\n",
    "    \n",
    "    \n",
    "    def kl(self):\n",
    "\n",
    "        return -0.5 * torch.sum(1 + 2*self.sigma.log() - self.mu.pow(2) - self.sigma**2, -1)\n",
    "        \n",
    "        \n",
    "    def log_posterior(self):\n",
    "        return Normal(self.mu, self.sigma).log_prob(self.z)\n",
    "        \n",
    "    def log_prior(self):\n",
    "        return Normal(torch.zeros_like(self.mu), torch.ones_like(self.sigma)).log_prob(self.z)\n",
    "        \n",
    "        \n",
    "    @staticmethod     \n",
    "    def nsample(mu, sigma, n = 1):\n",
    "        eps = Normal(torch.zeros_like(mu), torch.ones_like(mu)).sample_n(n)\n",
    "        return mu + eps*sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = None \n",
    "        self.decoder = None \n",
    "        self.reparametrize = []\n",
    "        self.r_callback = []\n",
    "        \n",
    "    def encode(self,x, n = 1):\n",
    "        \n",
    "        h = self.encoder(x)\n",
    "        z = [r(f(h), n) for r, f in zip(self.reparametrize, self.r_callback)]\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def kl(self):\n",
    "        # NOTE always call after encode\n",
    "        # TODO make this bahaviour impossible\n",
    "        kl = [r.kl() for r in self.reparametrize]\n",
    "        return kl\n",
    "        \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z) \n",
    "    \n",
    "    def forward(self, x, n=1):\n",
    "        z = self.encode(x, n=n)\n",
    "    \n",
    "        # flatten and stack z\n",
    "        z_cat = torch.cat([v.view(n, x.size()[0], -1) for v in z], -1)\n",
    "        \n",
    "        return self.decode(z_cat)\n",
    "    \n",
    "    \n",
    "    def recon_loss(self, x, x_recon):\n",
    "        raise NotImplemented \n",
    "    \n",
    "    def elbo(self, x):\n",
    "        x_recon = self.forward(x)[0]\n",
    "        kl = self.kl()\n",
    "        # TODO maybe sum directly  without stacking \n",
    "        kl_summed  = torch.sum(torch.stack(kl,-1), -1)\n",
    "        recon_loss = self.recon_loss(x, x_recon)\n",
    "        return recon_loss, kl_summed\n",
    "        \n",
    "        \n",
    "    def log_likelihood(self, x, n=1):\n",
    "        raise NotImplemented       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class S2ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, f_list = [1,10,10], b_list = [30,10,6], activation = nn.ReLU):\n",
    "        super(S2ConvNet, self).__init__()\n",
    "        \n",
    "        #TODO make boolean for integrate\n",
    "        grid_s2 = s2_near_identity_grid()\n",
    "        grid_so3 = so3_near_identity_grid()\n",
    "        \n",
    "        self.f_list = f_list\n",
    "        self.b_list = b_list\n",
    "        \n",
    "        #self.mlp_dim = mlp_dim.copy()\n",
    "        \n",
    "        #self.mlp_dim.insert(0, f_list[-1]*(b_list[-1]*2)**3)\n",
    "        #print(self.mlp_dim)\n",
    "        self.activation = activation\n",
    "\n",
    "        modules = []\n",
    "        conv1 = S2Convolution(\n",
    "            nfeature_in= f_list[0],\n",
    "            nfeature_out=f_list[1],\n",
    "            b_in=b_list[0],\n",
    "            b_out=b_list[1],\n",
    "            grid=grid_s2)\n",
    "        modules.append(conv1)\n",
    "        modules.append(self.activation())\n",
    "    \n",
    "        for f_in, f_out, b_in, b_out in zip(f_list[1:-1], f_list[2:], b_list[1:-1], b_list[2:]):\n",
    "            #print(f_in, f_out, b_in, b_out)\n",
    "            conv = SO3Convolution(\n",
    "                                    nfeature_in=f_in,\n",
    "                                    nfeature_out=f_out,\n",
    "                                    b_in=b_in,\n",
    "                                    b_out=b_out,\n",
    "                                    grid=grid_so3)\n",
    "            \n",
    "            modules.append(conv)\n",
    "            modules.append(self.activation())\n",
    "            \n",
    "        self.conv_module = nn.Sequential(*modules) \n",
    "        \n",
    "        #self.mlp_module = MLP(H = self.mlp_dim, activation = self.activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = self.conv_module(x)\n",
    "        #x = self.mlp_module(x.view(-1,self.mlp_dim[0]))\n",
    "       \n",
    "\n",
    "        #x = so3_integrate(x)\n",
    "\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class S2DeconvNet(nn.Module):\n",
    "\n",
    "    def __init__(self, f_list = [10,10,1], b_list = [5,10,30], mlp_dim = [10], activation = nn.ReLU):\n",
    "        super(S2DeconvNet, self).__init__()\n",
    "        #TODO make boolean for integrate\n",
    "        grid_s2 = s2_near_identity_grid()\n",
    "        grid_so3 = so3_near_identity_grid()\n",
    "        \n",
    "        self.f_list = f_list\n",
    "        self.b_list = b_list\n",
    "        self.mlp_dim = mlp_dim.copy()\n",
    "        self.mlp_dim.append( f_list[0]*(b_list[0]*2)**3)\n",
    "        print(self.mlp_dim)\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.mlp_module = MLP(H = self.mlp_dim, activation = self.activation)\n",
    "\n",
    "        modules = []\n",
    "        \n",
    "  \n",
    "        for f_in, f_out, b_in, b_out in zip(f_list[:-1], f_list[1:], b_list[:-1], b_list[1:]):\n",
    "        \n",
    "            modules.append(self.activation())\n",
    "            \n",
    "            if b_in < b_out:\n",
    "                modules.append(torch.nn.Upsample(size= b_out*2,  mode='nearest'))\n",
    "                \n",
    "            conv = SO3Convolution(\n",
    "                                    nfeature_in=f_in,\n",
    "                                    nfeature_out=f_out,\n",
    "                                    b_in=b_out,\n",
    "                                    b_out=b_out,\n",
    "                                    grid=grid_so3)\n",
    "            \n",
    "            modules.append(conv)\n",
    "            \n",
    "            \n",
    "        self.conv_module = nn.Sequential(*modules) \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.mlp_module(x)\n",
    "        shape = x.size()[:-1]\n",
    "        x = x.view(-1, self.f_list[0], self.b_list[0]*2, self.b_list[0]*2, self.b_list[0]*2)\n",
    "        \n",
    "        x = self.conv_module(x)\n",
    "        \n",
    "        x = x.view(*shape, self.f_list[-1], self.b_list[-1]*2, self.b_list[-1]*2, self.b_list[-1]*2)\n",
    "        \n",
    "       \n",
    "        \n",
    "       \n",
    "\n",
    "        #x = so3_integrate(x)\n",
    "\n",
    "        # TODO better reduce gamma channel\n",
    "        return x.mean(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NS2VAE(VAE):\n",
    "    def __init__(self, z_dim = 10,\n",
    "                       encoder_f=[1,10,10],\n",
    "                       decoder_f=[10,10,1],\n",
    "                       encoder_b=[30,20,6],\n",
    "                       decoder_b=[5,15,30],\n",
    "                       mlp_h=[100]):\n",
    "        super(NS2VAE, self).__init__() \n",
    "        \n",
    "        self.encoder = S2ConvNet(f_list = encoder_f, b_list = encoder_b)\n",
    "        self.decoder = S2DeconvNet(f_list = decoder_f, b_list = decoder_b, mlp_dim = [z_dim])\n",
    "        \n",
    "        self.mlp_h = mlp_h.copy()\n",
    "        self.mlp_h.insert(0, encoder_f[-1]*(encoder_b[-1]*2)**3)\n",
    "        self.mlp = MLP(H = self.mlp_h, end_activation = True)\n",
    "        \n",
    "        self.repar1 = Nreparametrize(mlp_h[-1], z_dim)\n",
    "        self.reparametrize = [self.repar1]\n",
    "        self.r_callback = [lambda x: self.mlp(x.view(-1, self.mlp_h[0]))] \n",
    "        \n",
    "        self.bce = nn.BCELoss(size_average=False)\n",
    "        \n",
    "    \n",
    "    def recon_loss(self, x, x_recon):\n",
    "        x_recon = F.sigmoid(x_recon)\n",
    "        b = x_recon.log() * x + (1 - x_recon).log() * (1 - x)\n",
    "        return -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vae = NS2VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path, batch_size):\n",
    "\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    train_data = torch.from_numpy(\n",
    "        dataset[\"train\"][\"images\"][:,None,:,:].astype(np.float32))\n",
    "    train_labels = torch.from_numpy(\n",
    "        dataset[\"train\"][\"labels\"].astype(np.int64))\n",
    "\n",
    "    mean = train_data.mean()\n",
    "    stdv = train_data.std()\n",
    "\n",
    "    train_dataset = data_utils.TensorDataset(train_data, train_labels)\n",
    "    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_data = torch.from_numpy(\n",
    "        dataset[\"test\"][\"images\"][:,None,:,:].astype(np.float32))\n",
    "    test_labels = torch.from_numpy(\n",
    "        dataset[\"test\"][\"labels\"].astype(np.int64))\n",
    "\n",
    "    test_dataset = data_utils.TensorDataset(test_data, test_labels)\n",
    "    test_loader = data_utils.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_ID = 0\n",
    "MNIST_PATH = \"./mnist_example/s2_mnist.gz\"\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 5e-3\n",
    "\n",
    "train_loader, test_loader, train_dataset, _ = load_data(\n",
    "        MNIST_PATH, BATCH_SIZE)\n",
    "\n",
    "torch.cuda.set_device(DEVICE_ID)\n",
    "\n",
    "vae = NS2VAE(z_dim = 30)\n",
    "\n",
    "print(\"#params\", sum([x.numel() for x in vae.parameters()]))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda(DEVICE_ID)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    vae.parameters(),\n",
    "    lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)/255\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda(DEVICE_ID)\n",
    "            labels = labels.cuda(DEVICE_ID)\n",
    "        \n",
    "        rec, kl = vae.elbo(images)\n",
    "\n",
    "        \n",
    "        elbo = (rec.sum(-1).sum(-1).sum(-1) + 0.1*kl ).mean()\n",
    "        \n",
    "        elbo.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(\"\\r elbo: %.4f\", (elbo.cpu().data.numpy()), end=\"\")\n",
    "        if epoch > 2:\n",
    "            lol()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vae(images)[0,7,0].cpu().data.numpy(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae(images)[0,0,0].cpu().data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
